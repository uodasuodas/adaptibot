{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Interactive Object Detection Debugging\n",
        "Simplified notebook for testing detection models with interactive controls\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup and imports\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import pipeline, AutoProcessor, AutoModelForZeroShotObjectDetection\n",
        "from PIL import Image\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Loaded google/owlvit-base-patch16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Loaded google/owlvit-base-patch32\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Loaded google/owlvit-large-patch14\n",
            "✅ Loaded GroundingDINO\n"
          ]
        }
      ],
      "source": [
        "# Detection Models Setup\n",
        "class DetectionManager:\n",
        "    def __init__(self):\n",
        "        self.detectors = {}\n",
        "        self.available_models = []\n",
        "        self.setup_models()\n",
        "    \n",
        "    def create_owl_detector(self, model_name):\n",
        "        \"\"\"Create OWL-ViT detector\"\"\"\n",
        "        device = 0 if torch.cuda.is_available() else -1\n",
        "        detector = pipeline(\n",
        "            \"zero-shot-object-detection\",\n",
        "            model=model_name,\n",
        "            device=device,\n",
        "            torch_dtype=torch.float16 if device >= 0 else torch.float32,\n",
        "        )\n",
        "        return detector\n",
        "    \n",
        "    def create_grounding_dino(self):\n",
        "        \"\"\"Create GroundingDINO detector\"\"\"\n",
        "        try:\n",
        "            processor = AutoProcessor.from_pretrained(\"IDEA-Research/grounding-dino-tiny\")\n",
        "            model = AutoModelForZeroShotObjectDetection.from_pretrained(\"IDEA-Research/grounding-dino-tiny\")\n",
        "            \n",
        "            def grounding_detect(image_path, candidate_labels):\n",
        "                image = Image.open(image_path)\n",
        "                text_prompt = \" . \".join(candidate_labels[:15]) + \" .\"\n",
        "                inputs = processor(images=image, text=text_prompt, return_tensors=\"pt\")\n",
        "                \n",
        "                with torch.no_grad():\n",
        "                    outputs = model(**inputs)\n",
        "                \n",
        "                # Get image size for post-processing\n",
        "                target_sizes = torch.tensor([image.size[::-1]])\n",
        "                \n",
        "                # Fixed post-processing call - remove unsupported arguments\n",
        "                try:\n",
        "                    # Try with threshold arguments (newer versions)\n",
        "                    results = processor.post_process_grounded_object_detection(\n",
        "                        outputs, inputs.input_ids, target_sizes=target_sizes,\n",
        "                        box_threshold=0.1, text_threshold=0.1\n",
        "                    )[0]\n",
        "                except TypeError:\n",
        "                    # Fallback for older versions without threshold arguments\n",
        "                    results = processor.post_process_grounded_object_detection(\n",
        "                        outputs, inputs.input_ids, target_sizes=target_sizes\n",
        "                    )[0]\n",
        "                \n",
        "                detections = []\n",
        "                if \"boxes\" in results and \"scores\" in results and \"labels\" in results:\n",
        "                    for box, score, label in zip(results[\"boxes\"], results[\"scores\"], results[\"labels\"]):\n",
        "                        # Apply manual threshold filtering\n",
        "                        if float(score) >= 0.1:\n",
        "                            # Handle both string labels and numeric indices\n",
        "                            if isinstance(label, str):\n",
        "                                # GroundingDINO returns text labels directly\n",
        "                                label_text = label.strip()\n",
        "                            else:\n",
        "                                # Fallback to index-based lookup\n",
        "                                label_idx = int(label)\n",
        "                                if label_idx < len(candidate_labels):\n",
        "                                    label_text = candidate_labels[label_idx]\n",
        "                                else:\n",
        "                                    label_text = \"object\"\n",
        "                            \n",
        "                            detections.append({\n",
        "                                \"box\": {\"xmin\": float(box[0]), \"ymin\": float(box[1]), \n",
        "                                       \"xmax\": float(box[2]), \"ymax\": float(box[3])},\n",
        "                                \"score\": float(score),\n",
        "                                \"label\": label_text\n",
        "                            })\n",
        "                \n",
        "                return detections\n",
        "            \n",
        "            return grounding_detect\n",
        "        except Exception as e:\n",
        "            print(f\"GroundingDINO not available: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def setup_models(self):\n",
        "        \"\"\"Setup all available models\"\"\"\n",
        "        owl_models = [\n",
        "            \"google/owlvit-base-patch16\",\n",
        "            \"google/owlvit-base-patch32\", \n",
        "            \"google/owlvit-large-patch14\"\n",
        "        ]\n",
        "        \n",
        "        for model_name in owl_models:\n",
        "            try:\n",
        "                self.detectors[model_name] = self.create_owl_detector(model_name)\n",
        "                self.available_models.append(model_name)\n",
        "                print(f\"✅ Loaded {model_name}\")\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Failed to load {model_name}: {e}\")\n",
        "        \n",
        "        # Try GroundingDINO\n",
        "        grounding_detector = self.create_grounding_dino()\n",
        "        if grounding_detector:\n",
        "            self.detectors[\"GroundingDINO\"] = grounding_detector\n",
        "            self.available_models.append(\"GroundingDINO\")\n",
        "            print(\"✅ Loaded GroundingDINO\")\n",
        "    \n",
        "    def detect(self, model_name, image_path, search_terms):\n",
        "        \"\"\"Run detection with specified model\"\"\"\n",
        "        if model_name not in self.detectors:\n",
        "            raise ValueError(f\"Model {model_name} not available\")\n",
        "        \n",
        "        detector = self.detectors[model_name]\n",
        "        \n",
        "        if model_name == \"GroundingDINO\":\n",
        "            return detector(image_path, search_terms)\n",
        "        else:\n",
        "            return detector(image_path, candidate_labels=search_terms)\n",
        "\n",
        "# Initialize detection manager\n",
        "detector_manager = DetectionManager()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization Functions\n",
        "def visualize_detections(image, detections, title=\"Detections\", confidence_threshold=0.1):\n",
        "    \"\"\"Visualize detections with bounding boxes\"\"\"\n",
        "    img_vis = image.copy()\n",
        "    colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), \n",
        "              (255, 0, 255), (0, 255, 255), (255, 128, 0), (128, 255, 0)]\n",
        "    \n",
        "    filtered_dets = [d for d in detections if d[\"score\"] >= confidence_threshold]\n",
        "    label_to_color = {}\n",
        "    color_idx = 0\n",
        "    \n",
        "    for det in filtered_dets:\n",
        "        label = det[\"label\"]\n",
        "        score = det[\"score\"]\n",
        "        box = det[\"box\"]\n",
        "        \n",
        "        if label not in label_to_color:\n",
        "            label_to_color[label] = colors[color_idx % len(colors)]\n",
        "            color_idx += 1\n",
        "        color = label_to_color[label]\n",
        "        \n",
        "        x1, y1, x2, y2 = int(box[\"xmin\"]), int(box[\"ymin\"]), int(box[\"xmax\"]), int(box[\"ymax\"])\n",
        "        thickness = max(2, int(score * 8))\n",
        "        cv2.rectangle(img_vis, (x1, y1), (x2, y2), color, thickness)\n",
        "        \n",
        "        text = f\"{label} {score:.3f}\"\n",
        "        text_scale = 0.6\n",
        "        text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, text_scale, 2)[0]\n",
        "        cv2.rectangle(img_vis, (x1, y1-text_size[1]-10), (x1+text_size[0]+10, y1), color, -1)\n",
        "        cv2.putText(img_vis, text, (x1+5, y1-5), cv2.FONT_HERSHEY_SIMPLEX, \n",
        "                   text_scale, (255, 255, 255), 2)\n",
        "    \n",
        "    img_rgb = cv2.cvtColor(img_vis, cv2.COLOR_BGR2RGB)\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    plt.imshow(img_rgb)\n",
        "    plt.title(f\"{title} - {len(filtered_dets)} objects (threshold ≥ {confidence_threshold:.2f})\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    \n",
        "    return filtered_dets\n",
        "\n",
        "def get_detection_summary(detections, confidence_threshold=0.1):\n",
        "    \"\"\"Get summary statistics of detections\"\"\"\n",
        "    filtered = [d for d in detections if d[\"score\"] >= confidence_threshold]\n",
        "    if not filtered:\n",
        "        return \"No detections above threshold\"\n",
        "    \n",
        "    label_counts = Counter([d['label'] for d in filtered])\n",
        "    summary = f\"Found {len(filtered)} detections:\\n\"\n",
        "    for label, count in label_counts.most_common():\n",
        "        avg_conf = np.mean([d['score'] for d in filtered if d['label'] == label])\n",
        "        summary += f\"  • {label}: {count} ({avg_conf:.3f} avg confidence)\\n\"\n",
        "    \n",
        "    return summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Interactive detector ready!\n"
          ]
        }
      ],
      "source": [
        "# Interactive Detection Interface\n",
        "class InteractiveDetector:\n",
        "    def __init__(self, image_paths, search_terms):\n",
        "        self.image_paths = image_paths\n",
        "        self.search_terms = search_terms\n",
        "        self.current_detections = {}\n",
        "        self.current_model = None\n",
        "        self.current_image_path = None\n",
        "        \n",
        "    def create_interface(self):\n",
        "        \"\"\"Create interactive widgets\"\"\"\n",
        "        # Image selection dropdown\n",
        "        image_options = [(os.path.basename(path), path) for path in self.image_paths]\n",
        "        image_dropdown = widgets.Dropdown(\n",
        "            options=image_options,\n",
        "            value=self.image_paths[0],\n",
        "            description='Image:',\n",
        "            style={'description_width': 'initial'}\n",
        "        )\n",
        "        \n",
        "        # Model selection dropdown\n",
        "        model_dropdown = widgets.Dropdown(\n",
        "            options=detector_manager.available_models,\n",
        "            value=detector_manager.available_models[0],\n",
        "            description='Model:',\n",
        "            style={'description_width': 'initial'}\n",
        "        )\n",
        "        \n",
        "        # Threshold slider\n",
        "        threshold_slider = widgets.FloatSlider(\n",
        "            value=0.15,\n",
        "            min=0.01,\n",
        "            max=1.0,\n",
        "            step=0.01,\n",
        "            description='Confidence Threshold:',\n",
        "            readout_format='.3f',\n",
        "            style={'description_width': 'initial'}\n",
        "        )\n",
        "        \n",
        "        # Max detections slider\n",
        "        max_detections_slider = widgets.IntSlider(\n",
        "            value=50,\n",
        "            min=1,\n",
        "            max=200,\n",
        "            step=1,\n",
        "            description='Max Detections:',\n",
        "            style={'description_width': 'initial'}\n",
        "        )\n",
        "        \n",
        "        # Run button\n",
        "        run_button = widgets.Button(\n",
        "            description='🔍 Run Detection',\n",
        "            button_style='success',\n",
        "            layout=widgets.Layout(width='150px', height='40px')\n",
        "        )\n",
        "        \n",
        "        # Output area\n",
        "        output = widgets.Output()\n",
        "        \n",
        "        def run_detection(button):\n",
        "            with output:\n",
        "                clear_output(wait=True)\n",
        "                \n",
        "                image_path = image_dropdown.value\n",
        "                model_name = model_dropdown.value\n",
        "                threshold = threshold_slider.value\n",
        "                max_dets = max_detections_slider.value\n",
        "                \n",
        "                print(f\"🔍 Running {model_name} detection...\")\n",
        "                print(f\"📁 Image: {os.path.basename(image_path)}\")\n",
        "                print(f\"📊 Threshold: {threshold:.3f}, Max detections: {max_dets}\")\n",
        "                \n",
        "                try:\n",
        "                    # Load image\n",
        "                    image = cv2.imread(image_path)\n",
        "                    if image is None:\n",
        "                        print(f\"❌ Error: Could not load image {image_path}\")\n",
        "                        return\n",
        "                    \n",
        "                    # Run detection\n",
        "                    detections = detector_manager.detect(model_name, image_path, self.search_terms)\n",
        "                    self.current_detections[model_name] = detections\n",
        "                    self.current_model = model_name\n",
        "                    self.current_image_path = image_path\n",
        "                    \n",
        "                    # Visualize results\n",
        "                    filtered_dets = visualize_detections(\n",
        "                        image, detections, \n",
        "                        title=f\"{model_name} Detection Results\",\n",
        "                        confidence_threshold=threshold\n",
        "                    )\n",
        "                    \n",
        "                    # Show summary\n",
        "                    print(\"📈 Detection Summary:\")\n",
        "                    print(get_detection_summary(detections, threshold))\n",
        "                    \n",
        "                    # Show detailed results if not too many\n",
        "                    if len(filtered_dets) <= 20:\n",
        "                        print(\"\\n📋 Detailed Results:\")\n",
        "                        for i, det in enumerate(sorted(filtered_dets, key=lambda x: x[\"score\"], reverse=True)[:max_dets]):\n",
        "                            box = det[\"box\"]\n",
        "                            print(f\"  {i+1:2d}. {det['label']:<20} {det['score']:.3f} \"\n",
        "                                  f\"[{box['xmin']:.0f},{box['ymin']:.0f},{box['xmax']:.0f},{box['ymax']:.0f}]\")\n",
        "                    \n",
        "                except Exception as e:\n",
        "                    print(f\"❌ Error: {e}\")\n",
        "        \n",
        "        # Connect button to function\n",
        "        run_button.on_click(run_detection)\n",
        "        \n",
        "        # Layout\n",
        "        controls = widgets.VBox([\n",
        "            widgets.HBox([image_dropdown, model_dropdown]),\n",
        "            widgets.HBox([threshold_slider, max_detections_slider]),\n",
        "            run_button\n",
        "        ])\n",
        "        \n",
        "        display(controls, output)\n",
        "        \n",
        "        return controls, output\n",
        "\n",
        "print(\"Interactive detector ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🎯 Interactive Detection Interface\n",
            "📁 Available images: 2016 images\n",
            "  1. Explorer_HD2K_SN36949228_15-51-04_R.png\n",
            "  2. Explorer_HD2K_SN36949228_09-43-28_L.png\n",
            "  3. Explorer_HD2K_SN36949228_09-43-28_R.png\n",
            "  4. Explorer_HD2K_SN36949228_09-43-39_L.png\n",
            "  5. Explorer_HD2K_SN36949228_09-43-39_R.png\n",
            "  ... and 2011 more images\n",
            "🔍 Search terms: 28 terms\n",
            "🤖 Available models: ['google/owlvit-base-patch16', 'google/owlvit-base-patch32', 'google/owlvit-large-patch14', 'GroundingDINO']\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a38ca99291ba44ea886a6bbaa325a9ce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HBox(children=(Dropdown(description='Image:', options=(('Explorer_HD2K_SN36949228_15-51-04_R.pn…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "07a89d9a2ded41ff9caa7cd0f530986b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✨ Instructions:\n",
            "1. Select an image from the dropdown\n",
            "2. Select a model from the dropdown\n",
            "3. Adjust the confidence threshold slider\n",
            "4. Set maximum detections limit\n",
            "5. Click 'Run Detection' to see results\n",
            "6. Try different images and models to compare performance!\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# 🎯 MAIN INTERACTIVE DETECTION CELL\n",
        "# Configure your settings below and run this cell\n",
        "\n",
        "# === CONFIGURATION ===\n",
        "# Add multiple image paths here\n",
        "IMAGE_PATHS = [\n",
        "    \"/home/ut-ai/ai-works/adaptibot/yolo_detect/processed/images/Explorer_HD2K_SN36949228_15-51-04_R.png\",\n",
        "]\n",
        "\n",
        "# Auto-discover more images in the processed/images directory\n",
        "processed_images_dir = \"/home/ut-ai/ai-works/adaptibot/yolo_detect/processed/images/\"\n",
        "if os.path.exists(processed_images_dir):\n",
        "    for filename in sorted(os.listdir(processed_images_dir)):\n",
        "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            full_path = os.path.join(processed_images_dir, filename)\n",
        "            if full_path not in IMAGE_PATHS:\n",
        "                IMAGE_PATHS.append(full_path)\n",
        "\n",
        "# Optimized search terms (focused on what's likely in the image)\n",
        "SEARCH_TERMS = [\n",
        "    # Generic terms (work best)\n",
        "    \"toy\", \"object\", \"container\", \"item\",\n",
        "    \n",
        "    # Specific objects\n",
        "    \"can\", \"soda can\", \"aluminum can\", \"beverage can\", \"cylinder\",\n",
        "    \"duck\", \"rubber duck\", \"toy duck\", \"yellow duck\", \"bath duck\",\n",
        "    \"cup\", \"mug\", \"glass\", \"drinking vessel\",\n",
        "    \"sponge\", \"cleaning sponge\", \"rectangular object\",\n",
        "    \"ball\", \"round ball\", \"sphere\", \"toy ball\",\n",
        "    \"vegetable\", \"fruit\", \"food item\"\n",
        "]\n",
        "\n",
        "print(f\"🎯 Interactive Detection Interface\")\n",
        "print(f\"📁 Available images: {len(IMAGE_PATHS)} images\")\n",
        "for i, path in enumerate(IMAGE_PATHS[:5]):  # Show first 5\n",
        "    print(f\"  {i+1}. {os.path.basename(path)}\")\n",
        "if len(IMAGE_PATHS) > 5:\n",
        "    print(f\"  ... and {len(IMAGE_PATHS)-5} more images\")\n",
        "    \n",
        "print(f\"🔍 Search terms: {len(SEARCH_TERMS)} terms\")\n",
        "print(f\"🤖 Available models: {detector_manager.available_models}\")\n",
        "\n",
        "# Create and launch interactive detector\n",
        "interactive_detector = InteractiveDetector(IMAGE_PATHS, SEARCH_TERMS)\n",
        "controls, output = interactive_detector.create_interface()\n",
        "\n",
        "print(\"\\n✨ Instructions:\")\n",
        "print(\"1. Select an image from the dropdown\")\n",
        "print(\"2. Select a model from the dropdown\")\n",
        "print(\"3. Adjust the confidence threshold slider\")\n",
        "print(\"4. Set maximum detections limit\")\n",
        "print(\"5. Click 'Run Detection' to see results\")\n",
        "print(\"6. Try different images and models to compare performance!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
